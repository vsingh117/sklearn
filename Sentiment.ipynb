{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emotional-donna",
   "metadata": {},
   "source": [
    "### Reference Video\n",
    "\n",
    "https://www.youtube.com/watch?v=M9Itm95JzL0&t=0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "superb-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE=\"NEGATIVE\"\n",
    "    NEUTRAL=\"NEUTRAL\"\n",
    "    POSITIVE=\"POSITIVE\"\n",
    "\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer :\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        \n",
    "        positive_shrunk = positive[0:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return[x.sentiment for x in self.reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "nuclear-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"Books_small_10000.json\"   #\"AmazonReviews.json\"\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        \n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "        \n",
    "reviews[5].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "lucky-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "choice-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(train)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "\n",
    "len(cont.reviews)\n",
    "#print(\"Sample training independent variable :: \",train[0].text)\n",
    "#print(\"Sample training output variable :: \",train[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "impressed-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n",
      "208\n",
      "208\n",
      "Number of rows with positive sentiment ::  436\n",
      "Number of rows with negative sentiment ::  436\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()  \n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x =  test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(\"Number of rows with positive sentiment :: \",train_y.count(Sentiment.POSITIVE))\n",
    "print(\"Number of rows with negative sentiment :: \",train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "portable-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "## Limitation of CountVectorizer gives equal weigtage to all words\n",
    "#count_vect = CountVectorizer()\n",
    "count_vect = TfidfVectorizer()\n",
    "train_x_vectors = count_vect.fit_transform(train_x)\n",
    "train_x_vectors.shape\n",
    "\n",
    "test_x_vector = count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "right-flash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soup..Er..Myrtle. Ms. Myrlte was talking to her dog Mtlock when Bettie Easton called. She called about the M.E.L.O.N.S (the letters stand for Mature Elegant Ladies Open Nice Suggestion) The first time she told me about it, I said it made us sound like old hookers.Bettie had been right about one thing.Doris Phillips met me at the door of the Soup kitchen just tickld pink to have a little help.Myrtle had discovered a identity theft ring but did not know who was doing it.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-timber",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "reverse-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just didn't get into it. If was interesting at first, but then it just seemed to ponder along. so\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "test_x_vector[0]\n",
    "\n",
    "clf_svm.predict(test_x_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "planned-slope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_out = clf_svm.predict(test_x_vector)\n",
    "pred_out[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "determined-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.82      0.81       208\n",
      "    POSITIVE       0.81      0.80      0.81       208\n",
      "\n",
      "    accuracy                           0.81       416\n",
      "   macro avg       0.81      0.81      0.81       416\n",
      "weighted avg       0.81      0.81      0.81       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [Sentiment.NEGATIVE , Sentiment.POSITIVE]  #  Sentiment.NEUTRAL ,\n",
    "print(classification_report(test_y, pred_out, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-galaxy",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "massive-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "dec_out = clf_dec.predict(test_x_vector)\n",
    "dec_out[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-boring",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "liked-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "clf_nb.fit(train_x_vectors.toarray(), train_y)\n",
    "\n",
    "nb_out = clf_nb.predict(test_x_vector.toarray())\n",
    "nb_out[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-allowance",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "incomplete-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "log_out = clf_log.predict(test_x_vector)\n",
    "log_out[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-office",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "stylish-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for SVM model is ::  0.8076923076923077\n",
      "Score for decision tree model is ::  0.6346153846153846\n",
      "Score for Naive bayes model is ::  0.6610576923076923\n",
      "Score for logistic model is ::  0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "## Mean accuracy\n",
    "\n",
    "print(\"Score for SVM model is :: \",clf_svm.score(test_x_vector, test_y))\n",
    "print(\"Score for decision tree model is :: \",clf_dec.score(test_x_vector, test_y))\n",
    "print(\"Score for Naive bayes model is :: \",clf_nb.score(test_x_vector.toarray(), test_y))\n",
    "print(\"Score for logistic model is :: \",clf_log.score(test_x_vector, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "committed-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score for SVM ::  [0.80582524 0.         0.80952381]\n",
      "F-score for decision tree ::  [0.62189055 0.         0.64651163]\n",
      "F-score naive bayes ::  [0.65693431 0.         0.66508314]\n",
      "F-score logistic regression ::  [0.80291971 0.         0.80760095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vijay S Chauhan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "C:\\Users\\Vijay S Chauhan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "C:\\Users\\Vijay S Chauhan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "C:\\Users\\Vijay S Chauhan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    }
   ],
   "source": [
    "## F score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F-score for SVM :: \",f1_score(test_y,pred_out, average=None, labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]))\n",
    "print(\"F-score for decision tree :: \",f1_score(test_y,dec_out, average=None, labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]))\n",
    "print(\"F-score naive bayes :: \",f1_score(test_y,nb_out, average=None, labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]))\n",
    "print(\"F-score logistic regression :: \",f1_score(test_y,log_out, average=None, labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "seventh-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'POSITIVE': 5611, 'NEUTRAL': 653, 'NEGATIVE': 436})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#train_y.count(Sentiment.POSITIVE)\n",
    "counter=collections.Counter(train_y)\n",
    "\n",
    "print(counter)\n",
    "# Counter({1: 4, 2: 4, 3: 2, 5: 2, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "written-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['I thoroughly enjoyed this, 5 stars', 'bad book do not buy','horrible waste of time']\n",
    "\n",
    "new_test = count_vect.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-springfield",
   "metadata": {},
   "source": [
    "## Tuning our model(with Grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "hindu-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear','rbf'), 'C':(1,4,8,16,32)}\n",
    "\n",
    "tuned_svm = svm.SVC()\n",
    "clf = GridSearchCV(tuned_svm, parameters, cv=5)\n",
    "\n",
    "clf.fit(train_x_vectors, train_y)\n",
    "\n",
    "#log_out = clf_log.predict(test_x_vector)\n",
    "#log_out[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fiscal-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Grid search model is ::  0.8197115384615384\n"
     ]
    }
   ],
   "source": [
    "print(\"Score for Grid search model is :: \",clf.score(test_x_vector, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-keyboard",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "smart-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./models/sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-policy",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "brave-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "pleased-friendly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out = loaded_clf.predict(test_x_vector)\n",
    "\n",
    "model_out[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "exclusive-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put together a Greek fisherman/half assed detective named Socrates with some questionable characters and the recipe is funny and entertaining.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[9])\n",
    "model_out[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "optical-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE]\n",
    "\n",
    "cm = confusion_matrix(test_y, model_out, labels=labels)\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "sn.heatmap(df_cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-pledge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
